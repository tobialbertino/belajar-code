data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/winequality-red.csv")
is.null(data)
md.pattern(data)
install.packages("mice")
library(mice)
md.pattern(data)
head.data
head(data)
library(infotheo)
install.packages("infotheo")
library(infotheo)
library(infotheo)
# No 2
library(infotheo)
head(data)
data$fixed.acidity = cut(data$fixed.acidity, 4, include.lowest = TRUE)
data$volatile.acidity = cut(data$volatile.acidity, 4, include.lowest = TRUE)
head(data)
data$fixed.acidity = cut(data$fixed.acidity, 4, include.lowest = TRUE)
data$fixed.acidity
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/winequality-red.csv")
is.null(data)
md.pattern(data)
# No 2
library(infotheo)
head(data)
data$fixed.acidity = cut(data$fixed.acidity, 4, include.lowest = TRUE)
data$fixed.acidity
data$volatile.acidity = cut(data$volatile.acidity, 3, include.lowest = TRUE)
data$volatile.acidity
# No 2
library(infotheo)
head(data)
# dengan library
ew.fixed.acidity =  discretize(data$fixed.acidity, "equalwidth", 4)
ew.fixed.acidity
head(ew.fixed.acidity)
# No 2
library(infotheo)
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/winequality-red.csv")
is.null(data)
md.pattern(data)
# No 2
library(infotheo)
head(data)
# dengan library
ew.fixed.acidity =  discretize(data$fixed.acidity, "equalwidth", 4)
head(ew.fixed.acidity)
ew.volatile.acidity =  discretize(data$volatile.acidity, "equalwidth", 3)
head(ew.volatile.acidity)
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/winequality-red.csv")
head(data)
# dengan library
ew.fixed.acidity =  discretize(data$fixed.acidity, "equalwidth", 4)
head(ew.fixed.acidity)
ew.fixed.acidity[1]
ew.fixed.acidity[2]
ew.fixed.acidity[1]
# gabungkan kolom
cbind(ew.fixed.acidity, ew.volatile.acidity)
data.new = cind(data, ew.fixed.acidity, ew.volatile.acidity)
data.new = cbind(data, ew.fixed.acidity, ew.volatile.acidity)
data_baru = cbind(data, ew.fixed.acidity, ew.volatile.acidity)
head(data_baru)
data_baru = cbind(data, ew.fixed.acidity="diskret", ew.volatile.acidity)
head(data_baru)
data_baru = cbind(data, ew.fixed.acidity="diskret", ew.volatile.acidity='BARU')
head(data_baru)
data_baru = cbind(data, BARU=ew.fixed.acidity, BARU2=ew.volatile.acidity)
head(data_baru)
# gabungkan kolom
data_baru = cbind(data, BARU=ew.fixed.acidity, BARU2=ew.volatile.acidity)
head(data_baru)
# gabungkan kolom
data_baru = cbind(data, ew.fixed.acidity="NAMA1", ew.volatile.acidity)
head(data_baru)
# gabungkan kolom
data_baru = cbind(data, "NAMA1"=ew.fixed.acidity, ew.volatile.acidity)
head(data_baru)
typeof(ew.fixed.acidity)
head(ew.fixed.acidity)
head(data_baru)
names(data_baru)[13] = "data13"
head(data_baru)
names(data_baru)[14] = "ew.volatile.acidity"
head(data_baru)
library(mice)
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/winequality-red.csv")
is.null(data)
md.pattern(data)
# No 2
library(infotheo)
head(data)
# dengan library
ew.fixed.acidity =  discretize(data$fixed.acidity, "equalwidth", 4)
head(ew.fixed.acidity)
ew.volatile.acidity =  discretize(data$volatile.acidity, "equalwidth", 3)
head(ew.volatile.acidity)
# gabungkan kolom
data_baru = cbind(data, ew.fixed.acidity, ew.volatile.acidity)
names(data_baru)[13] = "ew.fixed.acidity"
names(data_baru)[14] = "ew.volatile.acidity"
head(data_baru)
ew.fixed.acidity
max(ew.fixed.acidity)
max(ew.volatile.acidity)
install.packages("fpc")
install.packages("cluster")
data.head()
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/train.csv")
data.head()
head(data)
tail(data)
is.null(data)
md.pattern(data)
library(mice)
library(cluster)
library(fcp)
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/train.csv")
install.packages("fpc")
library(fpc)
library(mice)
library(cluster)
library(fcp)
library(fcp)
library(fpc)
clear
library(mice)
library(cluster)
library(fpc)
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/train.csv")
is.null(data)
md.pattern(data)
head(data)
# No 4
# ambil 40 data, hapus variabel class
idx <- sample(1:dim(data)[1], 40)
data_sample <- data[idx, ]
data$class = NULL
# hierarchical clustering dengan metodenya
hc_single <-hclust(dist(cancerSample), method="single")
# hierarchical clustering dengan metodenya
hc_single <-hclust(dist(data_sample), method="single")
hc_average <-hclust(dist(data_sample), method="ave")
hc_complete <-hclust(dist(data_sample), method="complete")
# plot
plot(hc_single, hang = -1, labels=iris$Species[idx])
# plot
plot(hc_single, hang = -1, labels=data$Class[idx])
library(mice)
library(cluster)
library(fpc)
# baca data
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/train.csv")
is.null(data)
md.pattern(data)
head(data)
# No 4
# ambil 40 data, hapus variabel class
idx <- sample(1:dim(data)[1], 40)
data_sample <- data[idx, ]
data$class = NULL
# hierarchical clustering dengan metodenya
hc_single <-hclust(dist(data_sample), method="single")
hc_average <-hclust(dist(data_sample), method="ave")
hc_complete <-hclust(dist(data_sample), method="complete")
# plot
plot(hc_single, hang = -1, labels=data$class[idx])
library(mice)
library(cluster)
library(fpc)
# baca data
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/train.csv")
is.null(data)
md.pattern(data)
head(data)
tail(data)
# No 4
# ambil 40 data, hapus variabel class
idx <- sample(1:dim(data)[1], 40)
data_sample <- data[idx, ]
data_sample$class = NULL
# hierarchical clustering dengan metodenya
hc_single <-hclust(dist(data_sample), method="single")
hc_average <-hclust(dist(data_sample), method="ave")
hc_complete <-hclust(dist(data_sample), method="complete")
# plot
plot(hc_single, hang = -1, labels=data$class[idx])
plot(hchc_average, hang = -1, labels=data$class[idx])
plot(hc_average, hang = -1, labels=data$class[idx])
plot(hc_complete, hang = -1, labels=data$class[idx])
# plot
plot(hc_single, hang = -1, labels=data$class[idx])
plot(hc_average, hang = -1, labels=data$class[idx])
plot(hc_complete, hang = -1, labels=data$class[idx])
#library(party)
#library(rpart)
#library(rpart.plot)
#library(caret)
#library(e1071)
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/nursery/nursery.csv")
data.head
data.head()
head(data)
View(data)
View(data)
df = as.data.frame(data)
# Lihat 6 baris pertama
head(df)
View(df)
View(df)
# Lihat banyaknya seluruh data
print(paste('Banyaknya seluruh data adalah', sum(df$parents), 'org.'))
# Lihat banyaknya seluruh data
print(paste('Banyaknya seluruh data adalah', len(df), 'item.'))
# Lihat banyaknya seluruh data
print(paste('Banyaknya seluruh data adalah', length(df), 'item.'))
# Lihat banyaknya seluruh data
print(paste('Banyaknya seluruh data adalah', length(row(df)), 'item.'))
# Lihat banyaknya seluruh data
print(paste('Banyaknya seluruh data adalah', row(df), 'item.'))
# Lihat banyaknya seluruh data
summary(df)
install.packages("arules")
library(arules)
nrow(df)
# Praproses data
# Ubah data hasil tabulasi menjadi per penumpang
## Ambil kolom selain "Freq"
cols <- colnames(df)
cols
nursery <- sapply(cols,
function(col) {
## Replikasi masing-masing nilai sebanyak "Freq"
rep(df[, col])
})
# Ubah matrix data menjadi data.frame
nursery <- as.data.frame(nursery)
# Ringkasan statistik
summary(nursery)
## Replikasi masing-masing nilai sebanyak "Freq"
rep(df[, col], nrow(df))
library(arules)
# baca data
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/nursery/nursery.csv")
head(data)
# Ubah data menjadi data.frame
df = as.data.frame(data)
# Lihat 6 baris pertama
head(df)
# Lihat info df
summary(df)
nrow(df)
#--------------------------------------------------------------------------------
rules = apriori(df)
see
discretize()
head(df)
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by="lift")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# Parameter yang akan diterapkan
params = list(minlen = 2,
support = 0.05,
confidence = 0.8)
# Terapkan algoritme
rules <- apriori(titanic,
parameter = params,
appearance = list(rhs = c('class=not_recom',
'class=very_recom',
'class=priority',
'class=spec_prior'),
default = 'lhs')
)
# Terapkan algoritme
rules <- apriori(df,
parameter = params,
appearance = list(rhs = c('class=not_recom',
'class=very_recom',
'class=priority',
'class=spec_prior'),
default = 'lhs')
)
rules <- sort(rules, by="lift")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
rules <- sort(rules, by="lift")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by="confidence")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
library(arules)
# baca data
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/nursery/nursery.csv")
head(data)
# Ubah data menjadi data.frame
df = as.data.frame(data)
# Lihat 6 baris pertama
head(df)
# Lihat info df
summary(df)
nrow(df)
# penerapan algoritme apriori
rules = apriori(df)
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by="confidence")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# Parameter yang akan diterapkan
params = list(minlen = 2,
support = 0.05,
confidence = 0.8)
# Terapkan algoritme
rules <- apriori(df,
parameter = params,
appearance = list(rhs = c('class=not_recom',
'class=very_recom',
'class=priority',
'class=spec_prior'),
default = 'lhs')
)
rules <- sort(rules, by="confidence")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# No 4
# Membentuk matriks hubungan subset
subset_matrix <- is.subset(rules, rules)
subset_matrix[lower.tri(subset_matrix)] <- FALSE
# Menentukan rules yang redundan
redundant <- colSums(subset_matrix) > 1
redundant
# Ambil rules yang tidak redundan
rules_pruned <- rules[!redundant]
inspect(rules_pruned)
install.packages("arulesViz")
library(arulesViz)
# Ambil rules yang tidak redundan
rules_pruned <- rules[!redundant]
inspect(rules_pruned)
# NO 5
plot(rules_pruned)
plot(rules_pruned, method='grouped')
plot(rules_pruned, method='graph')
plot(rules_pruned, method='graph', control=list(type='items'))
# NO 5
plot(rules_pruned)
plot(rules_pruned, method='grouped')
plot(rules_pruned, method='graph')
plot(rules_pruned, method='graph', control=list(type='items'))
library(arules)
library(arulesViz)
# baca data
data = read.csv("C:/Users/TOBI/Documents/Belajar_R/Daming/Dataset/nursery/nursery.csv")
head(data)
# Ubah data menjadi data.frame
df = as.data.frame(data)
# Lihat 6 baris pertama
head(df)
# Lihat info df
summary(df)
nrow(df)
rules = apriori(df)
# Urutkan rules berdasarkan "confidence"
rules <- sort(rules, by="confidence")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# Parameter yang akan diterapkan
params = list(minlen = 2,
support = 0.05,
confidence = 0.8)
# Terapkan algoritme
rules <- apriori(df,
parameter = params,
appearance = list(rhs = c('class=not_recom',
'class=very_recom',
'class=priority',
'class=spec_prior'),
default = 'lhs')
)
# Urutkan rules berdasarkan "confidence"
rules <- sort(rules, by="confidence")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# No 4
# Membentuk matriks hubungan subset
subset_matrix <- is.subset(rules, rules)
subset_matrix[lower.tri(subset_matrix)] <- FALSE
# Menentukan rules yang redundan
redundant <- colSums(subset_matrix) > 1
# Ambil rules yang tidak redundan
rules_pruned <- rules[!redundant]
inspect(rules_pruned)
